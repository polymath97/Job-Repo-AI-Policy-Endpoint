{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### this notebook is supposed to be run on google colaboratory and the last updated version is in google colab. the link to this colab is already sent to your SL2 email. https://colab.research.google.com/drive/1Iwb4GzmjeGXeoTJzN_oSHm-kCUEel_Ov?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai\n",
    "!pip install PyMuPDF\n",
    "!pip install masked_ai\n",
    "!pip install bert_score\n",
    "!pip install langchain\n",
    "!pip install langchain_openai\n",
    "!pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import fitz\n",
    "\n",
    "from google.colab import files\n",
    "from masked_ai.masker import Masker\n",
    "#from rouge_score import rouge_scorer\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from bert_score import BERTScorer\n",
    "from bert_score import score\n",
    "import re\n",
    "import langchain\n",
    "\n",
    "# callbacks openai\n",
    "from langchain_community.callbacks import get_openai_callback\n",
    "\n",
    "# loaders\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "# splits\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# prompts\n",
    "# from langchain import PromptTemplate, ConversationChain, LLMChain\n",
    "from langchain.chains import ConversationChain, LLMChain\n",
    "\n",
    "# vector stores\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# retrievers\n",
    "from langchain.chains import RetrievalQA, ConversationalRetrievalChain\n",
    "\n",
    "# json parser\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "# from langchain_community.embeddings import OpenAIEmbeddings\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "# from dotenv import load_dotenv\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_text(text):\n",
    "    # Remove html <a> tag\n",
    "    text = re.sub(r\"<a href[^>]*>([^<]+)</a>\", \" \", text)\n",
    "    text = re.sub(r\"<a rel[^>]*>([^<]+)</a>\", \" \", text)\n",
    "\n",
    "    # Remove image-related tags\n",
    "    text = re.sub(r\"<img[^>]*>\", \" \", text)\n",
    "    text = re.sub(r\"<figure[^>]*>.*?</figure>\", \" \", text)\n",
    "    # Remove image-related tags including .png extension\n",
    "    text = re.sub(r\"<img[^>]*>|<figure[^>]*>.*?</figure>|<[^>]*.png[^>]*>\", \" \", text)\n",
    "\n",
    "    # Replace specific domain\n",
    "    text = text.replace(\"WWW. QQGIAT .NET\", \" \")\n",
    "\n",
    "    # Replace special characters\n",
    "    text = text.replace(\"\\t\", \" \").replace(\"\\n\", \" \").replace(\"(\\r\", \" \").replace(\"&nbsp;\", \" \").replace(\"amp;\", \" \")\n",
    "\n",
    "    # Remove url link\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    text = re.sub(r\"www.\\S+\", \"\", text)\n",
    "\n",
    "    # Keep letters and numbers only\n",
    "    # text = re.sub(r\"[^a-zA-Z0-9\\s]\", \" \", text)\n",
    "    text = re.sub(r\"[^\\w\\s.,]\", \" \", text)\n",
    "\n",
    "    # Keep single spaces\n",
    "    text = re.sub(\" +\", \" \", text)\n",
    "\n",
    "    # Remove long sequences of periods, but keep single periods and other punctuation\n",
    "    text = re.sub(r\"(?<!\\w)\\.{3,}(?!\\w)\", \" \", text)  # Replace 3 or more periods not surrounded by word characters\n",
    "    text = re.sub(r\"(?<!\\w)\\.{2,}(?!\\w)\", \" \", text)  # Replace 2 or more periods not surrounded by word characters\n",
    "\n",
    "    # Remove sequences of 3 or more periods\n",
    "    text = re.sub(r\"\\.{3,}\", \" \", text)\n",
    "    text = re.sub(r\"\\. {3,}\", \" \", text)\n",
    "\n",
    "    # Keep single spaces\n",
    "    text = re.sub(\" +\", \" \", text)\n",
    "\n",
    "    # Define the pattern to match unwanted characters (copied)\n",
    "    pattern = re.compile(\n",
    "        r\"[\\n\\xe2\\x96\\xaa\\xe2\\x96\\xaa\\xe2\\x80\\x99\\xe2\\x80\\x9c\\xe2\\x80\\x9d\\xe2\\x80\\x9d\\xe2\\x96\\xba\\xe2\\x80\\x99\\xe2\\x80\\x99\\xe2\\x96\\xba\\xe2\\x80\\x9c\\xe2\\x80\\x9d\\xe2\\x80\\x9d\\xe2\\x80\\x9c]\")\n",
    "    # Use the pattern to substitute the unwanted characters with an empty string (copied)\n",
    "    text = re.sub(pattern, '', text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files(file_paths):\n",
    "    concatenated_text = \"\"\n",
    "\n",
    "    try:\n",
    "        for file_path in file_paths:\n",
    "            with fitz.open(file_path) as doc:\n",
    "                text = \"\"\n",
    "                for page_number in range(doc.page_count):\n",
    "                    text += doc.load_page(page_number).get_text()\n",
    "\n",
    "                concatenated_text += text + \"\\n\"\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle exceptions and return an error response\n",
    "        return f\"Error reading files: {e}\"\n",
    "\n",
    "    return concatenated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL INFERENCE AND EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma(persist_directory='/content/drive/MyDrive/commonwealth/embeddings_folders/embeddings_v3',\n",
    "                  embedding_function=OpenAIEmbeddings(openai_api_key='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'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload files\n",
    "uploaded_files = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = '/content/'\n",
    "\n",
    "# Get all files in the specified directory\n",
    "file_paths = [os.path.join(directory_path, file_name) for file_name in os.listdir(directory_path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = ['/content/CFM_Artificial_Intelligence_Report_03_HR-1.pdf','/content/data-breach-preparation-and-response.pdf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = read_files(file_paths)\n",
    "# clean up context\n",
    "clean_context = cleanup_text(context)\n",
    "# masking context\n",
    "masker = Masker(clean_context)\n",
    "masked_context = masker.masked_data\n",
    "context = masked_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_name = 'Australia'\n",
    "user_prompt = 'Generate policy document for AI Policy for Startups Industry in Australia'\n",
    "question = 'Policy Outline'\n",
    "    # @TODO: limit user prompt token\n",
    "    # @TODO: add if else from question (outline vs concept notes), or TBD to process at the same/different EP?\n",
    "    # OUTLINE VARIABELS\n",
    "\n",
    "outline_template = f\"\"\"\n",
    "***** {user_prompt}. \n",
    "***** \n",
    "***** : {country_name}. \n",
    "*****\n",
    "*****\n",
    "*****\n",
    "*****\n",
    "--------\n",
    "*****\n",
    "    \n",
    "1. *****\n",
    "- *****\n",
    "- *****\n",
    "- *****\n",
    "\n",
    "2. *****\n",
    "- *****\n",
    "- *****\n",
    "- *****\n",
    "\n",
    "3. *****\n",
    "- *****\n",
    "- *****\n",
    "- *****\n",
    "\n",
    "4. *****\n",
    "- *****\n",
    "- *****\n",
    "- *****\n",
    "\n",
    "5. *****\n",
    "- *****\n",
    "- *****\n",
    "- *****\n",
    "\n",
    "6. *****\n",
    "- *****\n",
    "- *****\n",
    "- *****\n",
    "\n",
    "7. *****\n",
    "- *****\n",
    "- *****\n",
    "- *****\n",
    "    \n",
    "8. *****\n",
    "- *****\n",
    "- *****\n",
    "- *****\n",
    "\n",
    "*****:\n",
    "- *****\n",
    "- *****\n",
    "- *****\n",
    "- *****\n",
    "  *****\n",
    "  {context}\n",
    "- *****\n",
    "- *****\n",
    "- *****\n",
    "--------------------------------------\n",
    "*****\n",
    "*****\n",
    "*****\n",
    "***** {question} *****.\n",
    "*****\n",
    "1. *****\n",
    "1.1 *****\n",
    "    *****\n",
    "1.2 *****\n",
    "    *****\n",
    "*****\n",
    "*****\n",
    "\"\"\"\n",
    "outline_max_tokens_suggested = 2000\n",
    "\n",
    "outline_chain = RetrievalQA.from_chain_type(\n",
    "    llm=ChatOpenAI(\n",
    "        model_name='gpt-4-1106-preview',\n",
    "        openai_api_key='*****',\n",
    "        max_tokens=outline_max_tokens_suggested,\n",
    "        timeout=90,\n",
    "    ),\n",
    "    retriever=vectordb.as_retriever(search_kwargs={'k': 7}),\n",
    "    return_source_documents=True,\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_outline = outline_chain.invoke(outline_template)['result']\n",
    "policy_outline = masker.unmask_data(policy_outline)\n",
    "\n",
    "policy_outline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_output = [policy_outline]\n",
    "reference_text = [clean_context]\n",
    "\n",
    "# base model roberta large \n",
    "P, R, F1 = score(generated_output, reference_text, lang='en', rescale_with_baseline=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'bert score PRECISION score : {P}')\n",
    "print(f'bert score RECALL score : {R}')\n",
    "print(f'bert score F1 score : {F1}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
